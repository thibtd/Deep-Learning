{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Neural networks from scratch in pytorch \n",
    "\n",
    "Here we explore the different ways to build models using pytorch. How to make a neural net, train it, save it's weights etc. The goal is to build up eperience with the library and then be able to rebuild the basic transformer architecture from Attention is All You Need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep things consistent we will keep on using the stanfordnlp/imdb dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /home/codespace/.python/current/lib/python3.12/site-packages (3.8.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (8.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (0.15.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (2.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (2.10.6)\n",
      "Requirement already satisfied: jinja2 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (75.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/codespace/.local/lib/python3.12/site-packages (from spacy) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/codespace/.python/current/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<1.3.0,>=1.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.2.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jinja2->spacy) (3.0.2)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/codespace/.local/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /home/codespace/.python/current/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/codespace/.python/current/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#%pip install torch torchvision torchaudio\n",
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from spacy.lang.en import English\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(\"stanfordnlp/imdb\", split=\"train\").to_pandas()\n",
    "test_dataset  = load_dataset(\"stanfordnlp/imdb\", split=\"test\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "We keep the punctuation and do not lowercase the text as it can remove useful information\n",
    "1. tokenization \n",
    "2. stop word removal \n",
    "3. lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/codespace/.python/current/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: click in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/codespace/.local/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the text (remove italic and so on)\n",
    "def clean(text):\n",
    "    text = re.sub(r'<br\\s*/?>', ' ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['cleaned_text'] = train_dataset.apply(lambda x: clean(x['text']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "train_dataset['text_token'] = train_dataset.apply(lambda x: word_tokenize(x['cleaned_text']),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "\n",
    "def remove_stopwords(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['text_nostop'] = train_dataset.apply(lambda x: remove_stopwords(x['text_token']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'rented',\n",
       " 'I',\n",
       " 'AM',\n",
       " 'CURIOUS-YELLOW',\n",
       " 'video',\n",
       " 'store',\n",
       " 'controversy',\n",
       " 'surrounded',\n",
       " 'first',\n",
       " 'released',\n",
       " '1967',\n",
       " '.',\n",
       " 'I',\n",
       " 'also',\n",
       " 'heard',\n",
       " 'first',\n",
       " 'seized',\n",
       " 'U.S.',\n",
       " 'customs',\n",
       " 'ever',\n",
       " 'tried',\n",
       " 'enter',\n",
       " 'country',\n",
       " ',',\n",
       " 'therefore',\n",
       " 'fan',\n",
       " 'films',\n",
       " 'considered',\n",
       " '``',\n",
       " 'controversial',\n",
       " \"''\",\n",
       " 'I',\n",
       " 'really',\n",
       " 'see',\n",
       " '.',\n",
       " 'The',\n",
       " 'plot',\n",
       " 'centered',\n",
       " 'around',\n",
       " 'young',\n",
       " 'Swedish',\n",
       " 'drama',\n",
       " 'student',\n",
       " 'named',\n",
       " 'Lena',\n",
       " 'wants',\n",
       " 'learn',\n",
       " 'everything',\n",
       " 'life',\n",
       " '.',\n",
       " 'In',\n",
       " 'particular',\n",
       " 'wants',\n",
       " 'focus',\n",
       " 'attentions',\n",
       " 'making',\n",
       " 'sort',\n",
       " 'documentary',\n",
       " 'average',\n",
       " 'Swede',\n",
       " 'thought',\n",
       " 'certain',\n",
       " 'political',\n",
       " 'issues',\n",
       " 'Vietnam',\n",
       " 'War',\n",
       " 'race',\n",
       " 'issues',\n",
       " 'United',\n",
       " 'States',\n",
       " '.',\n",
       " 'In',\n",
       " 'asking',\n",
       " 'politicians',\n",
       " 'ordinary',\n",
       " 'denizens',\n",
       " 'Stockholm',\n",
       " 'opinions',\n",
       " 'politics',\n",
       " ',',\n",
       " 'sex',\n",
       " 'drama',\n",
       " 'teacher',\n",
       " ',',\n",
       " 'classmates',\n",
       " ',',\n",
       " 'married',\n",
       " 'men',\n",
       " '.',\n",
       " 'What',\n",
       " 'kills',\n",
       " 'I',\n",
       " 'AM',\n",
       " 'CURIOUS-YELLOW',\n",
       " '40',\n",
       " 'years',\n",
       " 'ago',\n",
       " ',',\n",
       " 'considered',\n",
       " 'pornographic',\n",
       " '.',\n",
       " 'Really',\n",
       " ',',\n",
       " 'sex',\n",
       " 'nudity',\n",
       " 'scenes',\n",
       " 'far',\n",
       " ',',\n",
       " 'even',\n",
       " \"'s\",\n",
       " 'shot',\n",
       " 'like',\n",
       " 'cheaply',\n",
       " 'made',\n",
       " 'porno',\n",
       " '.',\n",
       " 'While',\n",
       " 'countrymen',\n",
       " 'mind',\n",
       " 'find',\n",
       " 'shocking',\n",
       " ',',\n",
       " 'reality',\n",
       " 'sex',\n",
       " 'nudity',\n",
       " 'major',\n",
       " 'staple',\n",
       " 'Swedish',\n",
       " 'cinema',\n",
       " '.',\n",
       " 'Even',\n",
       " 'Ingmar',\n",
       " 'Bergman',\n",
       " ',',\n",
       " 'arguably',\n",
       " 'answer',\n",
       " 'good',\n",
       " 'old',\n",
       " 'boy',\n",
       " 'John',\n",
       " 'Ford',\n",
       " ',',\n",
       " 'sex',\n",
       " 'scenes',\n",
       " 'films',\n",
       " '.',\n",
       " 'I',\n",
       " 'commend',\n",
       " 'filmmakers',\n",
       " 'fact',\n",
       " 'sex',\n",
       " 'shown',\n",
       " 'film',\n",
       " 'shown',\n",
       " 'artistic',\n",
       " 'purposes',\n",
       " 'rather',\n",
       " 'shock',\n",
       " 'people',\n",
       " 'make',\n",
       " 'money',\n",
       " 'shown',\n",
       " 'pornographic',\n",
       " 'theaters',\n",
       " 'America',\n",
       " '.',\n",
       " 'I',\n",
       " 'AM',\n",
       " 'CURIOUS-YELLOW',\n",
       " 'good',\n",
       " 'film',\n",
       " 'anyone',\n",
       " 'wanting',\n",
       " 'study',\n",
       " 'meat',\n",
       " 'potatoes',\n",
       " '(',\n",
       " 'pun',\n",
       " 'intended',\n",
       " ')',\n",
       " 'Swedish',\n",
       " 'cinema',\n",
       " '.',\n",
       " 'But',\n",
       " 'really',\n",
       " ',',\n",
       " 'film',\n",
       " \"n't\",\n",
       " 'much',\n",
       " 'plot',\n",
       " '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset['text_nostop'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/codespace/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "#defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    return lemm_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset['lemm'] = train_dataset.apply(lambda x: lemmatizer(x['text_nostop']),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text            I rented I AM CURIOUS-YELLOW from my video sto...\n",
       "label                                                           0\n",
       "cleaned_text    I rented I AM CURIOUS-YELLOW from my video sto...\n",
       "text_token      [I, rented, I, AM, CURIOUS-YELLOW, from, my, v...\n",
       "text_nostop     [I, rented, I, AM, CURIOUS-YELLOW, video, stor...\n",
       "lemm            [I, rented, I, AM, CURIOUS-YELLOW, video, stor...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf-idf to have vectors \n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "train_dataset_tfidf = vectorizer.fit_transform(train_dataset['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset['cleaned_text'] = test_dataset.apply(lambda x: clean(x['text']),axis=1)\n",
    "test_dataset_tfidf = vectorizer.fit_transform(test_dataset['cleaned_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 5000)\n",
      "(25000, 5000)\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset_tfidf.shape)\n",
    "print(test_dataset_tfidf.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = torch.tensor(train_dataset_tfidf.toarray(), dtype=torch.float32)  # Convert sparse matrix if needed\n",
    "train_y = torch.tensor(train_dataset['label'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = torch.tensor(test_dataset_tfidf.toarray(), dtype=torch.float32)  # Convert sparse matrix if needed\n",
    "test_y = torch.tensor(test_dataset['label'].values, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(TensorDataset(train_X,train_y), batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(TensorDataset(test_X, test_y), batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating models  \n",
    "1. Make a class that inherits from nn.Module \n",
    "2. in __init__ call super and define the flow of data through the layers. \n",
    "3. To make it faster add a call to check if there is gpu/mps or smtg available. If not then cpu will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,outpout_size):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(input_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size,outpout_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = train_X.shape[1]\n",
    "output_size = 2\n",
    "hidden_size = 265"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork(input_size=input_size,outpout_size=output_size,hidden_size=hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=5000, out_features=265, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=265, out_features=265, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=265, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(network.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.662477  [   64/25000]\n",
      "loss: 0.000015  [ 6464/25000]\n",
      "loss: 6.197498  [12864/25000]\n",
      "loss: 0.025205  [19264/25000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 2.477769 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 4.953206  [   64/25000]\n",
      "loss: 0.000012  [ 6464/25000]\n",
      "loss: 9.424225  [12864/25000]\n",
      "loss: 0.000405  [19264/25000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 4.721019 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 10.531206  [   64/25000]\n",
      "loss: 0.000024  [ 6464/25000]\n",
      "loss: 7.769588  [12864/25000]\n",
      "loss: 0.010652  [19264/25000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 4.637889 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 10.673346  [   64/25000]\n",
      "loss: 0.002333  [ 6464/25000]\n",
      "loss: 8.015435  [12864/25000]\n",
      "loss: 0.024591  [19264/25000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 4.651331 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 10.769074  [   64/25000]\n",
      "loss: 0.001840  [ 6464/25000]\n",
      "loss: 2.976347  [12864/25000]\n",
      "loss: 0.101130  [19264/25000]\n",
      "Test Error: \n",
      " Accuracy: 50.0%, Avg loss: 1.925944 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, network, loss_fn, optimizer)\n",
    "    test(test_loader, network, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {0:'negative',1:'positive'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0.,  ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(x,y)->dict[float,str]:\n",
    "    with torch.no_grad():\n",
    "        x = x.to(device)\n",
    "        logits = network(x)\n",
    "        probabilities = torch.nn.functional.softmax(logits,dim=0)\n",
    "        pred = probabilities.argmax(0).item()\n",
    "        predicted = classes[pred]\n",
    "        return {'probability':pred,'label':predicted}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability: 1, predicted: positive, actual: negative\n"
     ]
    }
   ],
   "source": [
    "x, y = test_X[0], test_dataset['label'].iloc[0]\n",
    "out= inference(x,y)\n",
    "print(f'probability: {out['probability']}, predicted: {out['label']}, actual: {classes[y]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ray in /home/codespace/.python/current/lib/python3.12/site-packages (2.42.1)\n",
      "Requirement already satisfied: click>=7.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from ray) (8.1.8)\n",
      "Requirement already satisfied: filelock in /home/codespace/.local/lib/python3.12/site-packages (from ray) (3.13.1)\n",
      "Requirement already satisfied: jsonschema in /home/codespace/.local/lib/python3.12/site-packages (from ray) (4.23.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /home/codespace/.python/current/lib/python3.12/site-packages (from ray) (1.1.0)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from ray) (24.2)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /home/codespace/.python/current/lib/python3.12/site-packages (from ray) (5.29.3)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.12/site-packages (from ray) (6.0.2)\n",
      "Requirement already satisfied: aiosignal in /home/codespace/.python/current/lib/python3.12/site-packages (from ray) (1.3.2)\n",
      "Requirement already satisfied: frozenlist in /home/codespace/.python/current/lib/python3.12/site-packages (from ray) (1.5.0)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from ray) (2.32.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema->ray) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema->ray) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema->ray) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/codespace/.local/lib/python3.12/site-packages (from jsonschema->ray) (0.22.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->ray) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->ray) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->ray) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->ray) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /home/codespace/.python/current/lib/python3.12/site-packages (8.1.5)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets) (8.30.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/codespace/.local/lib/python3.12/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/codespace/.python/current/lib/python3.12/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/codespace/.python/current/lib/python3.12/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: decorator in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (2.18.0)\n",
      "Requirement already satisfied: stack_data in /home/codespace/.local/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/codespace/.local/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/codespace/.local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /home/codespace/.local/lib/python3.12/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameterTuning(config:dict):\n",
    "    batch_size = config['batch_size']\n",
    "    train_loader = DataLoader(TensorDataset(train_X,train_y), batch_size=batch_size, shuffle=True)\n",
    "    model = NeuralNetwork(hidden_size=config[\"hidden_size\"])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    loss_fn= nn.CrossEntropyLoss()\n",
    "    train(dataloader=train_loader,model=model,loss_fn=loss_fn,optimizer=optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space = {\n",
    "    \"hidden_size\": tune.grid_search([128, 256, 512]),\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    \"batch_size\":tune.grid_search([16, 32, 64,128])\n",
    "}\n",
    "tuner = tune.Tuner(\n",
    "    hyperparameterTuning,\n",
    "    param_space=search_space,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** SIGTERM received at time=1740146318 on cpu 3 ***\n",
      "PC: @     0x7d7c47bddc1a  (unknown)  (unknown)\n",
      "    @     0x7d7c47db2420  (unknown)  (unknown)\n",
      "[2025-02-21 13:58:38,283 E 32368 32368] logging.cc:460: *** SIGTERM received at time=1740146318 on cpu 3 ***\n",
      "[2025-02-21 13:58:38,283 E 32368 32368] logging.cc:460: PC: @     0x7d7c47bddc1a  (unknown)  (unknown)\n",
      "[2025-02-21 13:58:38,284 E 32368 32368] logging.cc:460:     @     0x7d7c47db2420  (unknown)  (unknown)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "15",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "results = tuner.fit()\n",
    "print(results.get_best_result(metric=\"score\", mode=\"min\").config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

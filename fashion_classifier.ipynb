{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e71c1ff",
   "metadata": {},
   "source": [
    "# Multi class classification with CNN \n",
    "\n",
    "## Idea:\n",
    "- Build a CNN model to classify the images of the fashion MNIST dataset.\n",
    "- Use torchvision to build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8d29335",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thibtd/some fun/Deep-Learning/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import torch \n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split\n",
    "import numpy as np\n",
    "import optuna\n",
    "from optuna.trial import TrialState"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571fb6ae",
   "metadata": {},
   "source": [
    "### 1. Load and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1170b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3734da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fashionMnist_data = datasets.FashionMNIST('./data',train=True,download=True, transform= transform_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213dac52",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(fashionMnist_data,batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e86b29cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Look at shape of the data\n",
    "print(data_loader.dataset.data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35b540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "Range of data: 0 - 255\n"
     ]
    }
   ],
   "source": [
    "# inspect type and range of data \n",
    "print(type(data_loader.dataset.data))\n",
    "min_val = data_loader.dataset.data.min().item()\n",
    "max_val = data_loader.dataset.data.max().item()\n",
    "print(f'Range of data: {min_val} - {max_val}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "720c833c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.28604060411453247, Std: 0.35302427411079407\n"
     ]
    }
   ],
   "source": [
    "# Now let's normalize the data so that the pixel values are between 0 and 1\n",
    "# Start by computing the mean and standard deviation of the dataset\n",
    "mean = data_loader.dataset.data.float().mean() / max_val\n",
    "std = data_loader.dataset.data.float().std() / max_val\n",
    "print(f'Mean: {mean}, Std: {std}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe2239f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create a new transform pipeline that normalizes the data\n",
    "transform_pipeline_final = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((mean.item(),), (std.item(),))\n",
    "])\n",
    "# Create a new dataset with the normalized data\n",
    "fashionMnist_norm = datasets.FashionMNIST('./data', train=True, download=True, transform=transform_pipeline_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7830aa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new data loader\n",
    "data_loader_final = torch.utils.data.DataLoader(fashionMnist_norm,batch_size=1000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bcce38c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inspecting the actual transformed data from the DataLoader:\n",
      "Shape of image batch: torch.Size([1000, 1, 28, 28])\n",
      "Min pixel value (after ToTensor and Normalize): -0.8103\n",
      "Max pixel value (after ToTensor and Normalize): 2.0224\n",
      "Mean of first image in batch: 0.0434\n",
      "Std of first image in batch: 0.9084\n"
     ]
    }
   ],
   "source": [
    "print(\"Inspecting the actual transformed data from the DataLoader:\")\n",
    "input_shape = None\n",
    "for images, labels in data_loader_final:\n",
    "    # `images` here is the batch of data *after* all transforms have been applied\n",
    "    input_shape = images.shape\n",
    "    print(f\"Shape of image batch: {input_shape}\")\n",
    "    print(f\"Min pixel value (after ToTensor and Normalize): {images.min().item():.4f}\")\n",
    "    print(f\"Max pixel value (after ToTensor and Normalize): {images.max().item():.4f}\")\n",
    "    print(f\"Mean of first image in batch: {images[0].mean().item():.4f}\")\n",
    "    print(f\"Std of first image in batch: {images[0].std().item():.4f}\")\n",
    "    break # Just look at the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e058da78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_classes = np.size(data_loader_final.dataset.classes)\n",
    "input_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a6aef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "de831555",
   "metadata": {},
   "source": [
    "### 2. Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6261bb57",
   "metadata": {},
   "source": [
    "#### A simple CNN model\n",
    "Conv -> ReLu -> Maxpool -> Conv -> ReLu  -> Maxpool -> Flatten -> Linear -> ReLu -> Linear \n",
    "\n",
    "*Bold parameter values are learnable and here serve for the explanation and as a start point.*\n",
    "\n",
    "- input image is: (1,28,28). So each image has 1 channel and 28x28 pixels.  \n",
    "- Conv layer will take the input image and apply a filter to it. The filter will slide over the image and produce a feature map.  \n",
    "  we use *32* filters of size *3x3*, padding *1* and stride *1* ensure that the output size is the same as the input size.   \n",
    "  Dimensions: (32,28,28)  \n",
    "- Maxpool layer will take the feature map and reduce its size by taking the maximum value in each 2x2 block.  \n",
    "    Kernel size controls the factor of the dimension reduction. A kernel size of *2* will reduce the size by a factor of 2.  \n",
    "    Dimensions: (32,14,14)  \n",
    "- Conv layer will take the feature map and apply a filter to it. The filter will slide over the image and produce a feature map.  \n",
    "    we use *64* filters of size *3x3*, padding *1* and stride *1* ensure that the output size is the same as the input size.   \n",
    "    Dimensions: (64,14,14)  \n",
    "- Maxpool layer will take the feature map and reduce its size by taking the maximum value in each 2x2 block.  \n",
    "    Dimensions: (64,7,7)    \n",
    "(here we flatten the images but it's not included in the architecture)     \n",
    "- Fully connected layer that takes the flattened features and processes them  \n",
    " Input size == Flattened size == 64*7*7 == 3136  \n",
    " Output size == *128*  \n",
    "- Fully connected layer that takes the output of the previous layer and processes it  \n",
    " Input size == *128* (in the sense that the output of the previous layer is the input of this layer)   \n",
    " Output size == 10 (number of classes)  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "556adaf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28//4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "680a69e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    def __init__(self,input_shape:torch.Tensor, num_classes:int,kernel_size:int=3, stride:int=1):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        padding = kernel_size // 2 if stride == 1 else 0\n",
    "        max_pool_kernel = 2\n",
    "        in_channel = input_shape[1]\n",
    "        w,h = input_shape[2], input_shape[3]\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=in_channel, out_channels=32, kernel_size=kernel_size, stride=1, padding=padding)\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=max_pool_kernel, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=kernel_size, stride=1, padding=padding)\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=max_pool_kernel, stride=2)\n",
    "        self.fc1 = torch.nn.Linear(in_features=64* (w//(2*max_pool_kernel))*(h//(2*max_pool_kernel)), out_features=128)\n",
    "        self.fc2 = torch.nn.Linear(in_features=128, out_features=num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = torch.nn.functional.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539149d9",
   "metadata": {},
   "source": [
    "### 3. Train the model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df5f8cd",
   "metadata": {},
   "source": [
    "Since we are dealing with a multi-class classification problem, we will use the CrossEntropyLoss function.\n",
    "The CrossEntropyLoss function combines the softmax activation function and the negative log-likelihood loss function.\n",
    "It uses logits directly and output the probabilities of each class. So we can see the output as a probability distribution over the classes.\n",
    "Sensitive to class imbalance. --> we will check if we have any, if so we can use the class weights to balance the loss function.\n",
    "\n",
    "For the optimzer, we will use the Adam optimizer. It is a popular choice for training deep learning models. It is an adaptive learning rate optimization algorithm that can be used instead of the classical stochastic gradient descent (SGD) method. Great starting point for most problems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9fa03246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS (Metal Performance Shaders) is available! Using GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS (Metal Performance Shaders) is available! Using GPU.\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"MPS is not available. Falling back to CPU.\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0f794af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for class imbalance\n",
    "data_loader_final.dataset.targets.bincount()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d4d130",
   "metadata": {},
   "source": [
    "No imbalance in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "41b937cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=3136, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instance of the model and send it to device\n",
    "model = SimpleCNN(input_shape, number_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89ee4804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function and optimizer\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee90b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/val split \n",
    "train_size = int(0.8 * len(data_loader_final.dataset))\n",
    "val_size = len(data_loader_final.dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(data_loader_final.dataset, [train_size, val_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e850fe9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training parameters \n",
    "num_epochs = 5\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_acc = []\n",
    "val_acc = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e5841e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model \n",
    "def train_model(model, batch_size, num_epochs, lr):\n",
    "    train_size = int(0.8 * len(data_loader_final.dataset))\n",
    "    val_size = len(data_loader_final.dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(data_loader_final.dataset, [train_size, val_size])\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        # training phase \n",
    "        model.train()\n",
    "        training_running_loss = 0.0\n",
    "        training_running_correct = 0\n",
    "        training_running_total = 0\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            training_running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            training_running_total += labels.size(0)\n",
    "            training_running_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        avg_epoch_loss = training_running_loss / len(train_loader)\n",
    "        avg_epoch_acc = training_running_correct / training_running_total\n",
    "        train_loss.append(avg_epoch_loss)\n",
    "        train_acc.append(avg_epoch_acc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_epoch_loss:.4f}, Training Accuracy: {avg_epoch_acc:.4f}\")\n",
    "\n",
    "        # validation phase\n",
    "        model.eval()\n",
    "        validation_running_loss = 0.0\n",
    "        validation_running_correct = 0\n",
    "        validation_running_total = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                \n",
    "                validation_running_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                validation_running_total += labels.size(0)\n",
    "                validation_running_correct += (predicted == labels).sum().item()\n",
    "        validation_avg_epoch_loss = validation_running_loss / len(val_loader)\n",
    "        validation_avg_epoch_acc = validation_running_correct / validation_running_total\n",
    "        val_loss.append(validation_avg_epoch_loss)\n",
    "        val_acc.append(validation_avg_epoch_acc)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {validation_avg_epoch_loss:.4f}, Validation Accuracy: {validation_avg_epoch_acc:.4f}\")\n",
    "        print(\"-----------------------------------------------------\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3219522f",
   "metadata": {},
   "source": [
    "### 4. Evaluate the model\n",
    "- check the training and validation loss and accuracy. Overfitting?\n",
    "- Check the accuracy of the model on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8226b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig1 = plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11c8211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = datasets.FashionMNIST('./data', train=False, download=True, transform=transform_pipeline_final)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e353df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.2555, Test Accuracy: 0.9114\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# test on the test set\n",
    "test_running_loss = 0.0\n",
    "test_running_correct = 0\n",
    "test_running_total = 0\n",
    "\n",
    "for images, labels in test_loader:\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    loss = loss_fn(outputs, labels)\n",
    "    test_running_loss += loss.item()\n",
    "    test_running_total += labels.size(0)\n",
    "    test_running_correct += (predicted == labels).sum().item()\n",
    "    #print(f\"Predicted: {predicted}, Actual: {labels}\")\n",
    "    \n",
    "avg_test_loss = test_running_loss / len(test_loader)\n",
    "avg_test_acc = test_running_correct / test_running_total\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}, Test Accuracy: {avg_test_acc:.4f}\")\n",
    "print(\"-----------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f50fe08",
   "metadata": {},
   "source": [
    "### 5. Hyperparameter tuning \n",
    "We use the Optuna library to tune the hyperparameters of the model.\n",
    "- Batch size\n",
    "- learning rate\n",
    "- number of epochs\n",
    "- optmizer\n",
    "\n",
    "Architecture of the model:\n",
    "- size of the kernels\n",
    "- number of filters\n",
    "- early stopping ? \n",
    "\n",
    "First will start with a simple study that will modify the hyperparameters outside of the model. We won't change the architecture of the model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "295ae0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function to run the training and validation process \n",
    "def objective(trial,**args):\n",
    "    # Define the hyperparameters \n",
    "    batch_size = trial.suggest_int('batch_size', 16,256,16)\n",
    "    num_epochs= trial.suggest_int('num_epochs', 5,25,5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
    "\n",
    "    # Optimizer seems to have largest impact and Adam was generally better than SGD in preliminary tests. \n",
    "    #optimizer_trial = optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    \n",
    "\n",
    "    #device setup \n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "    print(f\"Trial {trial.number}: Using device: {device}, LR: {learning_rate:.6f}, Batch Size: {batch_size}, Epochs: {num_epochs}\")\n",
    "\n",
    "    # Load data and split into train and validation sets then create data loaders\n",
    "    full_train_dataset = datasets.FashionMNIST('./data', train=True, download=True, transform=transform_pipeline_final)\n",
    "    train_size = int(0.8 * len(full_train_dataset)) \n",
    "    val_size = len(full_train_dataset) - train_size\n",
    "\n",
    "    train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    input_shape = None\n",
    "    for images, labels in train_loader:\n",
    "        input_shape = images.shape\n",
    "        break\n",
    "\n",
    "    number_classes = np.size(train_loader.dataset.dataset.classes)\n",
    "\n",
    "    # Initialize the model\n",
    "    model = SimpleCNN(input_shape, number_classes)\n",
    "    model.to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    \n",
    "    # train the model \n",
    "    best_val_accuracy = 0.0 # To track best performance for pruning\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        correct_train_predictions = 0\n",
    "        total_train_samples = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total_train_samples += labels.size(0)\n",
    "            correct_train_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        train_accuracy = 100 * correct_train_predictions / total_train_samples\n",
    "\n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        correct_val_predictions = 0\n",
    "        total_val_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, labels)\n",
    "                running_val_loss += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total_val_samples += labels.size(0)\n",
    "                correct_val_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        avg_val_loss = running_val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * correct_val_predictions / total_val_samples\n",
    "\n",
    "        print(f\"  Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Train Acc = {train_accuracy:.2f}% | Val Loss = {avg_val_loss:.4f}, Val Acc = {val_accuracy:.2f}%\")\n",
    "\n",
    "       \n",
    "        best_val_accuracy = max(best_val_accuracy, val_accuracy)\n",
    "        trial.report(val_accuracy, epoch)\n",
    "\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return best_val_accuracy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "28a35315",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:19:07,817] Using an existing study with name 'fashion_mnist_cnn_hpo_study' instead of creating a new one.\n",
      "/var/folders/07/cbtj5f0s2_v0hy9qt2t1zqgc0000gn/T/ipykernel_4421/1134657496.py:4: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  batch_size = trial.suggest_int('batch_size', 16,256,16)\n",
      "/var/folders/07/cbtj5f0s2_v0hy9qt2t1zqgc0000gn/T/ipykernel_4421/1134657496.py:5: FutureWarning: suggest_int() got {'step'} as positional arguments but they were expected to be given as keyword arguments.\n",
      "  num_epochs= trial.suggest_int('num_epochs', 5,25,5)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Optuna Hyperparameter Optimization ---\n",
      "Trial 20: Using device: mps, LR: 0.000719, Batch Size: 112, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.5000, Train Acc = 82.17% | Val Loss = 0.3542, Val Acc = 87.55%\n",
      "  Epoch 2: Train Loss = 0.3190, Train Acc = 88.41% | Val Loss = 0.2984, Val Acc = 89.42%\n",
      "  Epoch 3: Train Loss = 0.2666, Train Acc = 90.39% | Val Loss = 0.2933, Val Acc = 89.22%\n",
      "  Epoch 4: Train Loss = 0.2367, Train Acc = 91.41% | Val Loss = 0.2552, Val Acc = 90.88%\n",
      "  Epoch 5: Train Loss = 0.2103, Train Acc = 92.37% | Val Loss = 0.2450, Val Acc = 91.21%\n",
      "  Epoch 6: Train Loss = 0.1896, Train Acc = 93.04% | Val Loss = 0.2711, Val Acc = 89.90%\n",
      "  Epoch 7: Train Loss = 0.1725, Train Acc = 93.71% | Val Loss = 0.2193, Val Acc = 92.15%\n",
      "  Epoch 8: Train Loss = 0.1515, Train Acc = 94.44% | Val Loss = 0.2234, Val Acc = 92.11%\n",
      "  Epoch 9: Train Loss = 0.1341, Train Acc = 95.07% | Val Loss = 0.2238, Val Acc = 92.22%\n",
      "  Epoch 10: Train Loss = 0.1192, Train Acc = 95.65% | Val Loss = 0.2431, Val Acc = 91.78%\n",
      "  Epoch 11: Train Loss = 0.1045, Train Acc = 96.24% | Val Loss = 0.2413, Val Acc = 91.67%\n",
      "  Epoch 12: Train Loss = 0.0928, Train Acc = 96.65% | Val Loss = 0.2405, Val Acc = 92.11%\n",
      "  Epoch 13: Train Loss = 0.0793, Train Acc = 97.22% | Val Loss = 0.2660, Val Acc = 92.05%\n",
      "  Epoch 14: Train Loss = 0.0699, Train Acc = 97.50% | Val Loss = 0.2744, Val Acc = 91.89%\n",
      "  Epoch 15: Train Loss = 0.0594, Train Acc = 97.90% | Val Loss = 0.2779, Val Acc = 92.16%\n",
      "  Epoch 16: Train Loss = 0.0485, Train Acc = 98.32% | Val Loss = 0.2825, Val Acc = 91.92%\n",
      "  Epoch 17: Train Loss = 0.0426, Train Acc = 98.52% | Val Loss = 0.3141, Val Acc = 91.93%\n",
      "  Epoch 18: Train Loss = 0.0396, Train Acc = 98.59% | Val Loss = 0.3275, Val Acc = 91.92%\n",
      "  Epoch 19: Train Loss = 0.0332, Train Acc = 98.92% | Val Loss = 0.3355, Val Acc = 92.04%\n",
      "  Epoch 20: Train Loss = 0.0284, Train Acc = 99.06% | Val Loss = 0.3441, Val Acc = 91.72%\n",
      "  Epoch 21: Train Loss = 0.0241, Train Acc = 99.19% | Val Loss = 0.3708, Val Acc = 92.02%\n",
      "  Epoch 22: Train Loss = 0.0179, Train Acc = 99.39% | Val Loss = 0.3831, Val Acc = 91.68%\n",
      "  Epoch 23: Train Loss = 0.0262, Train Acc = 99.04% | Val Loss = 0.4439, Val Acc = 91.56%\n",
      "  Epoch 24: Train Loss = 0.0164, Train Acc = 99.45% | Val Loss = 0.4071, Val Acc = 91.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:22:59,727] Trial 20 finished with value: 92.225 and parameters: {'batch_size': 112, 'num_epochs': 25, 'learning_rate': 0.0007190466784194314}. Best is trial 20 with value: 92.225.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25: Train Loss = 0.0173, Train Acc = 99.42% | Val Loss = 0.4017, Val Acc = 91.62%\n",
      "Trial 21: Using device: mps, LR: 0.001106, Batch Size: 112, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.4639, Train Acc = 83.25% | Val Loss = 0.3202, Val Acc = 88.64%\n",
      "  Epoch 2: Train Loss = 0.2958, Train Acc = 89.30% | Val Loss = 0.2773, Val Acc = 89.85%\n",
      "  Epoch 3: Train Loss = 0.2516, Train Acc = 90.79% | Val Loss = 0.2612, Val Acc = 90.43%\n",
      "  Epoch 4: Train Loss = 0.2181, Train Acc = 91.96% | Val Loss = 0.2334, Val Acc = 91.47%\n",
      "  Epoch 5: Train Loss = 0.1941, Train Acc = 92.70% | Val Loss = 0.2250, Val Acc = 91.80%\n",
      "  Epoch 6: Train Loss = 0.1731, Train Acc = 93.70% | Val Loss = 0.2251, Val Acc = 91.92%\n",
      "  Epoch 7: Train Loss = 0.1495, Train Acc = 94.53% | Val Loss = 0.2341, Val Acc = 91.82%\n",
      "  Epoch 8: Train Loss = 0.1336, Train Acc = 95.10% | Val Loss = 0.2390, Val Acc = 91.63%\n",
      "  Epoch 9: Train Loss = 0.1165, Train Acc = 95.69% | Val Loss = 0.2410, Val Acc = 92.02%\n",
      "  Epoch 10: Train Loss = 0.1015, Train Acc = 96.27% | Val Loss = 0.2407, Val Acc = 92.40%\n",
      "  Epoch 11: Train Loss = 0.0869, Train Acc = 96.80% | Val Loss = 0.2761, Val Acc = 91.52%\n",
      "  Epoch 12: Train Loss = 0.0743, Train Acc = 97.26% | Val Loss = 0.2807, Val Acc = 91.98%\n",
      "  Epoch 13: Train Loss = 0.0642, Train Acc = 97.62% | Val Loss = 0.2687, Val Acc = 91.93%\n",
      "  Epoch 14: Train Loss = 0.0531, Train Acc = 98.06% | Val Loss = 0.3067, Val Acc = 92.22%\n",
      "  Epoch 15: Train Loss = 0.0443, Train Acc = 98.38% | Val Loss = 0.3150, Val Acc = 92.21%\n",
      "  Epoch 16: Train Loss = 0.0404, Train Acc = 98.50% | Val Loss = 0.3378, Val Acc = 91.83%\n",
      "  Epoch 17: Train Loss = 0.0377, Train Acc = 98.65% | Val Loss = 0.3502, Val Acc = 91.74%\n",
      "  Epoch 18: Train Loss = 0.0328, Train Acc = 98.81% | Val Loss = 0.3925, Val Acc = 91.89%\n",
      "  Epoch 19: Train Loss = 0.0243, Train Acc = 99.11% | Val Loss = 0.3755, Val Acc = 92.39%\n",
      "  Epoch 20: Train Loss = 0.0211, Train Acc = 99.27% | Val Loss = 0.4018, Val Acc = 92.04%\n",
      "  Epoch 21: Train Loss = 0.0254, Train Acc = 99.07% | Val Loss = 0.4461, Val Acc = 91.90%\n",
      "  Epoch 22: Train Loss = 0.0216, Train Acc = 99.23% | Val Loss = 0.4247, Val Acc = 92.15%\n",
      "  Epoch 23: Train Loss = 0.0184, Train Acc = 99.34% | Val Loss = 0.4399, Val Acc = 91.78%\n",
      "  Epoch 24: Train Loss = 0.0167, Train Acc = 99.40% | Val Loss = 0.4484, Val Acc = 91.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:26:47,976] Trial 21 finished with value: 92.4 and parameters: {'batch_size': 112, 'num_epochs': 25, 'learning_rate': 0.0011060294840424371}. Best is trial 21 with value: 92.4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25: Train Loss = 0.0230, Train Acc = 99.24% | Val Loss = 0.4483, Val Acc = 91.96%\n",
      "Trial 22: Using device: mps, LR: 0.001627, Batch Size: 128, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.4589, Train Acc = 83.52% | Val Loss = 0.3240, Val Acc = 88.23%\n",
      "  Epoch 2: Train Loss = 0.2913, Train Acc = 89.13% | Val Loss = 0.2672, Val Acc = 90.03%\n",
      "  Epoch 3: Train Loss = 0.2403, Train Acc = 91.17% | Val Loss = 0.2342, Val Acc = 91.52%\n",
      "  Epoch 4: Train Loss = 0.2090, Train Acc = 92.29% | Val Loss = 0.2196, Val Acc = 92.14%\n",
      "  Epoch 5: Train Loss = 0.1813, Train Acc = 93.14% | Val Loss = 0.2074, Val Acc = 92.57%\n",
      "  Epoch 6: Train Loss = 0.1568, Train Acc = 94.15% | Val Loss = 0.2330, Val Acc = 91.68%\n",
      "  Epoch 7: Train Loss = 0.1355, Train Acc = 94.93% | Val Loss = 0.2158, Val Acc = 92.68%\n",
      "  Epoch 8: Train Loss = 0.1147, Train Acc = 95.71% | Val Loss = 0.2350, Val Acc = 92.06%\n",
      "  Epoch 9: Train Loss = 0.0973, Train Acc = 96.38% | Val Loss = 0.2273, Val Acc = 92.73%\n",
      "  Epoch 10: Train Loss = 0.0824, Train Acc = 96.96% | Val Loss = 0.2546, Val Acc = 92.40%\n",
      "  Epoch 11: Train Loss = 0.0686, Train Acc = 97.47% | Val Loss = 0.2746, Val Acc = 92.18%\n",
      "  Epoch 12: Train Loss = 0.0599, Train Acc = 97.84% | Val Loss = 0.2900, Val Acc = 91.47%\n",
      "  Epoch 13: Train Loss = 0.0493, Train Acc = 98.14% | Val Loss = 0.3341, Val Acc = 91.82%\n",
      "  Epoch 14: Train Loss = 0.0422, Train Acc = 98.42% | Val Loss = 0.3547, Val Acc = 91.91%\n",
      "  Epoch 15: Train Loss = 0.0361, Train Acc = 98.69% | Val Loss = 0.3710, Val Acc = 92.08%\n",
      "  Epoch 16: Train Loss = 0.0340, Train Acc = 98.81% | Val Loss = 0.3953, Val Acc = 92.05%\n",
      "  Epoch 17: Train Loss = 0.0353, Train Acc = 98.75% | Val Loss = 0.3982, Val Acc = 91.74%\n",
      "  Epoch 18: Train Loss = 0.0282, Train Acc = 99.01% | Val Loss = 0.4024, Val Acc = 91.87%\n",
      "  Epoch 19: Train Loss = 0.0250, Train Acc = 99.10% | Val Loss = 0.4384, Val Acc = 92.12%\n",
      "  Epoch 20: Train Loss = 0.0245, Train Acc = 99.13% | Val Loss = 0.4480, Val Acc = 91.94%\n",
      "  Epoch 21: Train Loss = 0.0279, Train Acc = 98.97% | Val Loss = 0.5045, Val Acc = 91.67%\n",
      "  Epoch 22: Train Loss = 0.0222, Train Acc = 99.22% | Val Loss = 0.4553, Val Acc = 92.03%\n",
      "  Epoch 23: Train Loss = 0.0214, Train Acc = 99.27% | Val Loss = 0.4502, Val Acc = 92.12%\n",
      "  Epoch 24: Train Loss = 0.0181, Train Acc = 99.36% | Val Loss = 0.4835, Val Acc = 91.97%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:30:23,849] Trial 22 finished with value: 92.73333333333333 and parameters: {'batch_size': 128, 'num_epochs': 25, 'learning_rate': 0.0016269594651740216}. Best is trial 22 with value: 92.73333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25: Train Loss = 0.0189, Train Acc = 99.35% | Val Loss = 0.5391, Val Acc = 92.12%\n",
      "Trial 23: Using device: mps, LR: 0.002064, Batch Size: 144, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.4564, Train Acc = 83.39% | Val Loss = 0.3431, Val Acc = 87.75%\n",
      "  Epoch 2: Train Loss = 0.2790, Train Acc = 89.84% | Val Loss = 0.2604, Val Acc = 90.69%\n",
      "  Epoch 3: Train Loss = 0.2304, Train Acc = 91.57% | Val Loss = 0.2425, Val Acc = 91.18%\n",
      "  Epoch 4: Train Loss = 0.1978, Train Acc = 92.67% | Val Loss = 0.2455, Val Acc = 91.40%\n",
      "  Epoch 5: Train Loss = 0.1719, Train Acc = 93.56% | Val Loss = 0.2308, Val Acc = 91.95%\n",
      "  Epoch 6: Train Loss = 0.1474, Train Acc = 94.43% | Val Loss = 0.2370, Val Acc = 91.59%\n",
      "  Epoch 7: Train Loss = 0.1264, Train Acc = 95.34% | Val Loss = 0.2474, Val Acc = 91.80%\n",
      "  Epoch 8: Train Loss = 0.1105, Train Acc = 95.87% | Val Loss = 0.2536, Val Acc = 92.08%\n",
      "  Epoch 9: Train Loss = 0.0930, Train Acc = 96.54% | Val Loss = 0.2747, Val Acc = 91.97%\n",
      "  Epoch 10: Train Loss = 0.0807, Train Acc = 97.01% | Val Loss = 0.3163, Val Acc = 90.85%\n",
      "  Epoch 11: Train Loss = 0.0676, Train Acc = 97.52% | Val Loss = 0.3053, Val Acc = 91.75%\n",
      "  Epoch 12: Train Loss = 0.0606, Train Acc = 97.77% | Val Loss = 0.3235, Val Acc = 91.94%\n",
      "  Epoch 13: Train Loss = 0.0512, Train Acc = 98.08% | Val Loss = 0.3487, Val Acc = 92.04%\n",
      "  Epoch 14: Train Loss = 0.0409, Train Acc = 98.52% | Val Loss = 0.3945, Val Acc = 91.53%\n",
      "  Epoch 15: Train Loss = 0.0391, Train Acc = 98.52% | Val Loss = 0.3859, Val Acc = 92.08%\n",
      "  Epoch 16: Train Loss = 0.0341, Train Acc = 98.73% | Val Loss = 0.4132, Val Acc = 91.70%\n",
      "  Epoch 17: Train Loss = 0.0324, Train Acc = 98.81% | Val Loss = 0.4509, Val Acc = 91.37%\n",
      "  Epoch 18: Train Loss = 0.0286, Train Acc = 98.96% | Val Loss = 0.4824, Val Acc = 91.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:33:01,468] Trial 23 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 19: Train Loss = 0.0347, Train Acc = 98.76% | Val Loss = 0.4999, Val Acc = 91.54%\n",
      "Trial 24: Using device: mps, LR: 0.001205, Batch Size: 112, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.4565, Train Acc = 83.79% | Val Loss = 0.3581, Val Acc = 87.08%\n",
      "  Epoch 2: Train Loss = 0.2960, Train Acc = 89.34% | Val Loss = 0.2787, Val Acc = 89.84%\n",
      "  Epoch 3: Train Loss = 0.2480, Train Acc = 90.96% | Val Loss = 0.2507, Val Acc = 90.71%\n",
      "  Epoch 4: Train Loss = 0.2156, Train Acc = 92.14% | Val Loss = 0.2591, Val Acc = 90.64%\n",
      "  Epoch 5: Train Loss = 0.1896, Train Acc = 93.04% | Val Loss = 0.2308, Val Acc = 91.46%\n",
      "  Epoch 6: Train Loss = 0.1651, Train Acc = 93.91% | Val Loss = 0.2370, Val Acc = 91.48%\n",
      "  Epoch 7: Train Loss = 0.1458, Train Acc = 94.54% | Val Loss = 0.2325, Val Acc = 91.99%\n",
      "  Epoch 8: Train Loss = 0.1274, Train Acc = 95.23% | Val Loss = 0.2527, Val Acc = 91.26%\n",
      "  Epoch 9: Train Loss = 0.1099, Train Acc = 95.94% | Val Loss = 0.2449, Val Acc = 92.00%\n",
      "  Epoch 10: Train Loss = 0.0944, Train Acc = 96.51% | Val Loss = 0.2521, Val Acc = 91.74%\n",
      "  Epoch 11: Train Loss = 0.0810, Train Acc = 96.98% | Val Loss = 0.2631, Val Acc = 91.85%\n",
      "  Epoch 12: Train Loss = 0.0637, Train Acc = 97.72% | Val Loss = 0.2791, Val Acc = 92.06%\n",
      "  Epoch 13: Train Loss = 0.0572, Train Acc = 97.95% | Val Loss = 0.2798, Val Acc = 92.20%\n",
      "  Epoch 14: Train Loss = 0.0495, Train Acc = 98.24% | Val Loss = 0.3308, Val Acc = 91.19%\n",
      "  Epoch 15: Train Loss = 0.0435, Train Acc = 98.41% | Val Loss = 0.3316, Val Acc = 91.98%\n",
      "  Epoch 16: Train Loss = 0.0367, Train Acc = 98.67% | Val Loss = 0.3630, Val Acc = 91.81%\n",
      "  Epoch 17: Train Loss = 0.0329, Train Acc = 98.82% | Val Loss = 0.3830, Val Acc = 91.49%\n",
      "  Epoch 18: Train Loss = 0.0254, Train Acc = 99.09% | Val Loss = 0.4035, Val Acc = 91.91%\n",
      "  Epoch 19: Train Loss = 0.0252, Train Acc = 99.07% | Val Loss = 0.4299, Val Acc = 91.34%\n",
      "  Epoch 20: Train Loss = 0.0288, Train Acc = 98.96% | Val Loss = 0.4110, Val Acc = 91.87%\n",
      "  Epoch 21: Train Loss = 0.0183, Train Acc = 99.37% | Val Loss = 0.4346, Val Acc = 91.74%\n",
      "  Epoch 22: Train Loss = 0.0161, Train Acc = 99.42% | Val Loss = 0.4729, Val Acc = 91.39%\n",
      "  Epoch 23: Train Loss = 0.0245, Train Acc = 99.14% | Val Loss = 0.4655, Val Acc = 91.97%\n",
      "  Epoch 24: Train Loss = 0.0191, Train Acc = 99.27% | Val Loss = 0.5183, Val Acc = 91.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:36:48,736] Trial 24 finished with value: 92.2 and parameters: {'batch_size': 112, 'num_epochs': 25, 'learning_rate': 0.001205060961851098}. Best is trial 22 with value: 92.73333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25: Train Loss = 0.0195, Train Acc = 99.30% | Val Loss = 0.4774, Val Acc = 91.94%\n",
      "Trial 25: Using device: mps, LR: 0.009390, Batch Size: 176, Epochs: 20\n",
      "  Epoch 1: Train Loss = 0.5375, Train Acc = 80.93% | Val Loss = 0.3752, Val Acc = 86.31%\n",
      "  Epoch 2: Train Loss = 0.3401, Train Acc = 87.59% | Val Loss = 0.3312, Val Acc = 87.79%\n",
      "  Epoch 3: Train Loss = 0.3066, Train Acc = 88.67% | Val Loss = 0.3178, Val Acc = 87.97%\n",
      "  Epoch 4: Train Loss = 0.2864, Train Acc = 89.36% | Val Loss = 0.3131, Val Acc = 88.64%\n",
      "  Epoch 5: Train Loss = 0.2723, Train Acc = 89.82% | Val Loss = 0.3046, Val Acc = 89.00%\n",
      "  Epoch 6: Train Loss = 0.2618, Train Acc = 90.18% | Val Loss = 0.3012, Val Acc = 89.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:37:44,773] Trial 25 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 7: Train Loss = 0.2564, Train Acc = 90.39% | Val Loss = 0.3218, Val Acc = 88.11%\n",
      "Trial 26: Using device: mps, LR: 0.000613, Batch Size: 112, Epochs: 20\n",
      "  Epoch 1: Train Loss = 0.5038, Train Acc = 82.11% | Val Loss = 0.3443, Val Acc = 87.66%\n",
      "  Epoch 2: Train Loss = 0.3254, Train Acc = 88.24% | Val Loss = 0.3037, Val Acc = 89.18%\n",
      "  Epoch 3: Train Loss = 0.2846, Train Acc = 89.70% | Val Loss = 0.2784, Val Acc = 90.22%\n",
      "  Epoch 4: Train Loss = 0.2549, Train Acc = 90.77% | Val Loss = 0.2567, Val Acc = 90.62%\n",
      "  Epoch 5: Train Loss = 0.2317, Train Acc = 91.54% | Val Loss = 0.2443, Val Acc = 91.26%\n",
      "  Epoch 6: Train Loss = 0.2116, Train Acc = 92.30% | Val Loss = 0.2512, Val Acc = 91.03%\n",
      "  Epoch 7: Train Loss = 0.1905, Train Acc = 92.91% | Val Loss = 0.2611, Val Acc = 90.50%\n",
      "  Epoch 8: Train Loss = 0.1786, Train Acc = 93.44% | Val Loss = 0.2402, Val Acc = 91.38%\n",
      "  Epoch 9: Train Loss = 0.1648, Train Acc = 93.97% | Val Loss = 0.2419, Val Acc = 91.29%\n",
      "  Epoch 10: Train Loss = 0.1498, Train Acc = 94.53% | Val Loss = 0.2231, Val Acc = 92.13%\n",
      "  Epoch 11: Train Loss = 0.1353, Train Acc = 94.99% | Val Loss = 0.2380, Val Acc = 91.86%\n",
      "  Epoch 12: Train Loss = 0.1225, Train Acc = 95.54% | Val Loss = 0.2497, Val Acc = 91.35%\n",
      "  Epoch 13: Train Loss = 0.1100, Train Acc = 96.00% | Val Loss = 0.2430, Val Acc = 91.98%\n",
      "  Epoch 14: Train Loss = 0.0991, Train Acc = 96.40% | Val Loss = 0.2478, Val Acc = 91.72%\n",
      "  Epoch 15: Train Loss = 0.0882, Train Acc = 96.85% | Val Loss = 0.2567, Val Acc = 91.97%\n",
      "  Epoch 16: Train Loss = 0.0788, Train Acc = 97.17% | Val Loss = 0.2641, Val Acc = 91.67%\n",
      "  Epoch 17: Train Loss = 0.0713, Train Acc = 97.43% | Val Loss = 0.2564, Val Acc = 92.01%\n",
      "  Epoch 18: Train Loss = 0.0609, Train Acc = 97.79% | Val Loss = 0.2814, Val Acc = 92.03%\n",
      "  Epoch 19: Train Loss = 0.0513, Train Acc = 98.17% | Val Loss = 0.2908, Val Acc = 91.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:40:47,673] Trial 26 finished with value: 92.13333333333334 and parameters: {'batch_size': 112, 'num_epochs': 20, 'learning_rate': 0.0006126193155533825}. Best is trial 22 with value: 92.73333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 20: Train Loss = 0.0447, Train Acc = 98.46% | Val Loss = 0.3158, Val Acc = 91.89%\n",
      "Trial 27: Using device: mps, LR: 0.000226, Batch Size: 112, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.6186, Train Acc = 78.94% | Val Loss = 0.4323, Val Acc = 85.01%\n",
      "  Epoch 2: Train Loss = 0.3932, Train Acc = 85.94% | Val Loss = 0.3642, Val Acc = 86.95%\n",
      "  Epoch 3: Train Loss = 0.3447, Train Acc = 87.78% | Val Loss = 0.3442, Val Acc = 87.91%\n",
      "  Epoch 4: Train Loss = 0.3152, Train Acc = 88.86% | Val Loss = 0.3054, Val Acc = 89.47%\n",
      "  Epoch 5: Train Loss = 0.2966, Train Acc = 89.47% | Val Loss = 0.3002, Val Acc = 89.58%\n",
      "  Epoch 6: Train Loss = 0.2788, Train Acc = 89.94% | Val Loss = 0.2898, Val Acc = 89.60%\n",
      "  Epoch 7: Train Loss = 0.2636, Train Acc = 90.44% | Val Loss = 0.2672, Val Acc = 90.34%\n",
      "  Epoch 8: Train Loss = 0.2521, Train Acc = 90.83% | Val Loss = 0.2588, Val Acc = 90.78%\n",
      "  Epoch 9: Train Loss = 0.2377, Train Acc = 91.30% | Val Loss = 0.2573, Val Acc = 90.91%\n",
      "  Epoch 10: Train Loss = 0.2287, Train Acc = 91.72% | Val Loss = 0.2514, Val Acc = 90.95%\n",
      "  Epoch 11: Train Loss = 0.2184, Train Acc = 92.12% | Val Loss = 0.2636, Val Acc = 90.66%\n",
      "  Epoch 12: Train Loss = 0.2081, Train Acc = 92.51% | Val Loss = 0.2393, Val Acc = 91.51%\n",
      "  Epoch 13: Train Loss = 0.2003, Train Acc = 92.69% | Val Loss = 0.2372, Val Acc = 91.47%\n",
      "  Epoch 14: Train Loss = 0.1919, Train Acc = 93.07% | Val Loss = 0.2393, Val Acc = 91.26%\n",
      "  Epoch 15: Train Loss = 0.1840, Train Acc = 93.34% | Val Loss = 0.2264, Val Acc = 91.88%\n",
      "  Epoch 16: Train Loss = 0.1773, Train Acc = 93.49% | Val Loss = 0.2361, Val Acc = 91.08%\n",
      "  Epoch 17: Train Loss = 0.1672, Train Acc = 94.02% | Val Loss = 0.2215, Val Acc = 92.03%\n",
      "  Epoch 18: Train Loss = 0.1618, Train Acc = 94.18% | Val Loss = 0.2193, Val Acc = 92.12%\n",
      "  Epoch 19: Train Loss = 0.1574, Train Acc = 94.25% | Val Loss = 0.2232, Val Acc = 92.20%\n",
      "  Epoch 20: Train Loss = 0.1499, Train Acc = 94.62% | Val Loss = 0.2172, Val Acc = 92.32%\n",
      "  Epoch 21: Train Loss = 0.1417, Train Acc = 94.92% | Val Loss = 0.2173, Val Acc = 92.47%\n",
      "  Epoch 22: Train Loss = 0.1357, Train Acc = 95.14% | Val Loss = 0.2201, Val Acc = 92.30%\n",
      "  Epoch 23: Train Loss = 0.1288, Train Acc = 95.41% | Val Loss = 0.2325, Val Acc = 91.70%\n",
      "  Epoch 24: Train Loss = 0.1254, Train Acc = 95.48% | Val Loss = 0.2273, Val Acc = 92.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:44:34,884] Trial 27 finished with value: 92.46666666666667 and parameters: {'batch_size': 112, 'num_epochs': 25, 'learning_rate': 0.0002255114543930892}. Best is trial 22 with value: 92.73333333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25: Train Loss = 0.1183, Train Acc = 95.79% | Val Loss = 0.2266, Val Acc = 92.26%\n",
      "Trial 28: Using device: mps, LR: 0.000290, Batch Size: 240, Epochs: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:44:42,625] Trial 28 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: Train Loss = 0.6795, Train Acc = 76.77% | Val Loss = 0.4824, Val Acc = 82.91%\n",
      "Trial 29: Using device: mps, LR: 0.003788, Batch Size: 160, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.4521, Train Acc = 83.61% | Val Loss = 0.3277, Val Acc = 88.23%\n",
      "  Epoch 2: Train Loss = 0.2794, Train Acc = 89.76% | Val Loss = 0.2650, Val Acc = 90.29%\n",
      "  Epoch 3: Train Loss = 0.2308, Train Acc = 91.54% | Val Loss = 0.2677, Val Acc = 90.36%\n",
      "  Epoch 4: Train Loss = 0.1986, Train Acc = 92.55% | Val Loss = 0.2715, Val Acc = 90.33%\n",
      "  Epoch 5: Train Loss = 0.1729, Train Acc = 93.47% | Val Loss = 0.2461, Val Acc = 91.23%\n",
      "  Epoch 6: Train Loss = 0.1475, Train Acc = 94.41% | Val Loss = 0.2495, Val Acc = 91.75%\n",
      "  Epoch 7: Train Loss = 0.1343, Train Acc = 94.92% | Val Loss = 0.2561, Val Acc = 91.67%\n",
      "  Epoch 8: Train Loss = 0.1171, Train Acc = 95.52% | Val Loss = 0.2718, Val Acc = 91.51%\n",
      "  Epoch 9: Train Loss = 0.1003, Train Acc = 96.28% | Val Loss = 0.3378, Val Acc = 90.75%\n",
      "  Epoch 10: Train Loss = 0.0906, Train Acc = 96.67% | Val Loss = 0.3046, Val Acc = 91.69%\n",
      "  Epoch 11: Train Loss = 0.0778, Train Acc = 97.09% | Val Loss = 0.3265, Val Acc = 91.62%\n",
      "  Epoch 12: Train Loss = 0.0727, Train Acc = 97.30% | Val Loss = 0.3861, Val Acc = 91.03%\n",
      "  Epoch 13: Train Loss = 0.0667, Train Acc = 97.56% | Val Loss = 0.3580, Val Acc = 91.78%\n",
      "  Epoch 14: Train Loss = 0.0587, Train Acc = 97.86% | Val Loss = 0.3805, Val Acc = 91.19%\n",
      "  Epoch 15: Train Loss = 0.0575, Train Acc = 97.88% | Val Loss = 0.4500, Val Acc = 91.05%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:46:52,008] Trial 29 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 16: Train Loss = 0.0513, Train Acc = 98.19% | Val Loss = 0.4730, Val Acc = 91.15%\n",
      "Trial 30: Using device: mps, LR: 0.000206, Batch Size: 192, Epochs: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:47:00,873] Trial 30 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: Train Loss = 0.7224, Train Acc = 75.79% | Val Loss = 0.4817, Val Acc = 83.04%\n",
      "Trial 31: Using device: mps, LR: 0.000780, Batch Size: 112, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.4860, Train Acc = 82.50% | Val Loss = 0.3292, Val Acc = 88.27%\n",
      "  Epoch 2: Train Loss = 0.3109, Train Acc = 88.72% | Val Loss = 0.2694, Val Acc = 90.51%\n",
      "  Epoch 3: Train Loss = 0.2631, Train Acc = 90.38% | Val Loss = 0.2406, Val Acc = 91.56%\n",
      "  Epoch 4: Train Loss = 0.2312, Train Acc = 91.55% | Val Loss = 0.2458, Val Acc = 91.40%\n",
      "  Epoch 5: Train Loss = 0.2077, Train Acc = 92.44% | Val Loss = 0.2502, Val Acc = 90.78%\n",
      "  Epoch 6: Train Loss = 0.1881, Train Acc = 93.07% | Val Loss = 0.2245, Val Acc = 91.90%\n",
      "  Epoch 7: Train Loss = 0.1696, Train Acc = 93.80% | Val Loss = 0.2129, Val Acc = 92.39%\n",
      "  Epoch 8: Train Loss = 0.1507, Train Acc = 94.59% | Val Loss = 0.2191, Val Acc = 92.35%\n",
      "  Epoch 9: Train Loss = 0.1349, Train Acc = 95.01% | Val Loss = 0.2332, Val Acc = 92.11%\n",
      "  Epoch 10: Train Loss = 0.1176, Train Acc = 95.62% | Val Loss = 0.2291, Val Acc = 92.21%\n",
      "  Epoch 11: Train Loss = 0.1046, Train Acc = 96.20% | Val Loss = 0.2200, Val Acc = 92.92%\n",
      "  Epoch 12: Train Loss = 0.0884, Train Acc = 96.83% | Val Loss = 0.2272, Val Acc = 92.60%\n",
      "  Epoch 13: Train Loss = 0.0790, Train Acc = 97.10% | Val Loss = 0.2538, Val Acc = 92.53%\n",
      "  Epoch 14: Train Loss = 0.0700, Train Acc = 97.49% | Val Loss = 0.2530, Val Acc = 92.83%\n",
      "  Epoch 15: Train Loss = 0.0574, Train Acc = 98.01% | Val Loss = 0.2527, Val Acc = 92.96%\n",
      "  Epoch 16: Train Loss = 0.0487, Train Acc = 98.26% | Val Loss = 0.2675, Val Acc = 92.80%\n",
      "  Epoch 17: Train Loss = 0.0412, Train Acc = 98.50% | Val Loss = 0.3087, Val Acc = 92.40%\n",
      "  Epoch 18: Train Loss = 0.0356, Train Acc = 98.79% | Val Loss = 0.3028, Val Acc = 92.58%\n",
      "  Epoch 19: Train Loss = 0.0334, Train Acc = 98.85% | Val Loss = 0.3060, Val Acc = 92.86%\n",
      "  Epoch 20: Train Loss = 0.0247, Train Acc = 99.19% | Val Loss = 0.3316, Val Acc = 92.42%\n",
      "  Epoch 21: Train Loss = 0.0272, Train Acc = 99.09% | Val Loss = 0.3335, Val Acc = 92.38%\n",
      "  Epoch 22: Train Loss = 0.0231, Train Acc = 99.24% | Val Loss = 0.3588, Val Acc = 92.63%\n",
      "  Epoch 23: Train Loss = 0.0204, Train Acc = 99.25% | Val Loss = 0.3807, Val Acc = 92.45%\n",
      "  Epoch 24: Train Loss = 0.0195, Train Acc = 99.30% | Val Loss = 0.4009, Val Acc = 92.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:50:52,311] Trial 31 finished with value: 92.95833333333333 and parameters: {'batch_size': 112, 'num_epochs': 25, 'learning_rate': 0.0007801093520990975}. Best is trial 31 with value: 92.95833333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25: Train Loss = 0.0150, Train Acc = 99.52% | Val Loss = 0.3978, Val Acc = 92.41%\n",
      "Trial 32: Using device: mps, LR: 0.000565, Batch Size: 96, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.5093, Train Acc = 81.85% | Val Loss = 0.3725, Val Acc = 86.65%\n",
      "  Epoch 2: Train Loss = 0.3302, Train Acc = 88.19% | Val Loss = 0.3040, Val Acc = 89.13%\n",
      "  Epoch 3: Train Loss = 0.2847, Train Acc = 89.70% | Val Loss = 0.2896, Val Acc = 89.64%\n",
      "  Epoch 4: Train Loss = 0.2540, Train Acc = 90.76% | Val Loss = 0.2707, Val Acc = 90.10%\n",
      "  Epoch 5: Train Loss = 0.2296, Train Acc = 91.63% | Val Loss = 0.2556, Val Acc = 90.76%\n",
      "  Epoch 6: Train Loss = 0.2116, Train Acc = 92.16% | Val Loss = 0.2545, Val Acc = 90.58%\n",
      "  Epoch 7: Train Loss = 0.1917, Train Acc = 92.97% | Val Loss = 0.2529, Val Acc = 90.92%\n",
      "  Epoch 8: Train Loss = 0.1751, Train Acc = 93.64% | Val Loss = 0.2362, Val Acc = 91.62%\n",
      "  Epoch 9: Train Loss = 0.1597, Train Acc = 93.96% | Val Loss = 0.2576, Val Acc = 90.72%\n",
      "  Epoch 10: Train Loss = 0.1436, Train Acc = 94.57% | Val Loss = 0.2243, Val Acc = 91.92%\n",
      "  Epoch 11: Train Loss = 0.1345, Train Acc = 95.02% | Val Loss = 0.2434, Val Acc = 91.83%\n",
      "  Epoch 12: Train Loss = 0.1173, Train Acc = 95.80% | Val Loss = 0.2436, Val Acc = 92.13%\n",
      "  Epoch 13: Train Loss = 0.1079, Train Acc = 96.01% | Val Loss = 0.2377, Val Acc = 91.87%\n",
      "  Epoch 14: Train Loss = 0.0979, Train Acc = 96.41% | Val Loss = 0.2598, Val Acc = 91.67%\n",
      "  Epoch 15: Train Loss = 0.0841, Train Acc = 96.96% | Val Loss = 0.2572, Val Acc = 91.74%\n",
      "  Epoch 16: Train Loss = 0.0755, Train Acc = 97.33% | Val Loss = 0.2684, Val Acc = 91.87%\n",
      "  Epoch 17: Train Loss = 0.0656, Train Acc = 97.61% | Val Loss = 0.2869, Val Acc = 91.33%\n",
      "  Epoch 18: Train Loss = 0.0566, Train Acc = 97.98% | Val Loss = 0.2998, Val Acc = 92.00%\n",
      "  Epoch 19: Train Loss = 0.0508, Train Acc = 98.12% | Val Loss = 0.3164, Val Acc = 92.05%\n",
      "  Epoch 20: Train Loss = 0.0434, Train Acc = 98.44% | Val Loss = 0.3324, Val Acc = 91.81%\n",
      "  Epoch 21: Train Loss = 0.0408, Train Acc = 98.58% | Val Loss = 0.3522, Val Acc = 91.44%\n",
      "  Epoch 22: Train Loss = 0.0371, Train Acc = 98.68% | Val Loss = 0.3432, Val Acc = 91.72%\n",
      "  Epoch 23: Train Loss = 0.0289, Train Acc = 99.07% | Val Loss = 0.3650, Val Acc = 91.62%\n",
      "  Epoch 24: Train Loss = 0.0294, Train Acc = 98.99% | Val Loss = 0.3882, Val Acc = 91.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:54:57,119] Trial 32 finished with value: 92.13333333333334 and parameters: {'batch_size': 96, 'num_epochs': 25, 'learning_rate': 0.0005646096632661883}. Best is trial 31 with value: 92.95833333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25: Train Loss = 0.0264, Train Acc = 99.10% | Val Loss = 0.3796, Val Acc = 91.76%\n",
      "Trial 33: Using device: mps, LR: 0.001980, Batch Size: 128, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.4443, Train Acc = 83.83% | Val Loss = 0.3221, Val Acc = 88.38%\n",
      "  Epoch 2: Train Loss = 0.2743, Train Acc = 89.99% | Val Loss = 0.2602, Val Acc = 90.67%\n",
      "  Epoch 3: Train Loss = 0.2237, Train Acc = 91.74% | Val Loss = 0.2713, Val Acc = 89.96%\n",
      "  Epoch 4: Train Loss = 0.1940, Train Acc = 92.84% | Val Loss = 0.2428, Val Acc = 91.17%\n",
      "  Epoch 5: Train Loss = 0.1702, Train Acc = 93.76% | Val Loss = 0.2350, Val Acc = 91.58%\n",
      "  Epoch 6: Train Loss = 0.1441, Train Acc = 94.67% | Val Loss = 0.2569, Val Acc = 91.42%\n",
      "  Epoch 7: Train Loss = 0.1238, Train Acc = 95.40% | Val Loss = 0.2523, Val Acc = 91.89%\n",
      "  Epoch 8: Train Loss = 0.1047, Train Acc = 96.00% | Val Loss = 0.2807, Val Acc = 91.62%\n",
      "  Epoch 9: Train Loss = 0.0851, Train Acc = 96.86% | Val Loss = 0.2642, Val Acc = 91.92%\n",
      "  Epoch 10: Train Loss = 0.0737, Train Acc = 97.27% | Val Loss = 0.3008, Val Acc = 91.49%\n",
      "  Epoch 11: Train Loss = 0.0618, Train Acc = 97.69% | Val Loss = 0.3219, Val Acc = 91.52%\n",
      "  Epoch 12: Train Loss = 0.0524, Train Acc = 98.11% | Val Loss = 0.3123, Val Acc = 91.76%\n",
      "  Epoch 13: Train Loss = 0.0443, Train Acc = 98.36% | Val Loss = 0.3728, Val Acc = 91.44%\n",
      "  Epoch 14: Train Loss = 0.0410, Train Acc = 98.55% | Val Loss = 0.3883, Val Acc = 91.39%\n",
      "  Epoch 15: Train Loss = 0.0427, Train Acc = 98.50% | Val Loss = 0.3920, Val Acc = 91.47%\n",
      "  Epoch 16: Train Loss = 0.0345, Train Acc = 98.67% | Val Loss = 0.4181, Val Acc = 91.61%\n",
      "  Epoch 17: Train Loss = 0.0299, Train Acc = 98.91% | Val Loss = 0.4728, Val Acc = 91.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:57:35,342] Trial 33 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 18: Train Loss = 0.0236, Train Acc = 99.19% | Val Loss = 0.4651, Val Acc = 90.95%\n",
      "Trial 34: Using device: mps, LR: 0.000166, Batch Size: 96, Epochs: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 14:57:45,126] Trial 34 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: Train Loss = 0.6194, Train Acc = 78.54% | Val Loss = 0.4514, Val Acc = 83.57%\n",
      "Trial 35: Using device: mps, LR: 0.001062, Batch Size: 96, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.4447, Train Acc = 83.92% | Val Loss = 0.3384, Val Acc = 87.73%\n",
      "  Epoch 2: Train Loss = 0.2877, Train Acc = 89.58% | Val Loss = 0.2806, Val Acc = 89.74%\n",
      "  Epoch 3: Train Loss = 0.2431, Train Acc = 91.02% | Val Loss = 0.2372, Val Acc = 91.22%\n",
      "  Epoch 4: Train Loss = 0.2087, Train Acc = 92.25% | Val Loss = 0.2292, Val Acc = 91.54%\n",
      "  Epoch 5: Train Loss = 0.1797, Train Acc = 93.34% | Val Loss = 0.2195, Val Acc = 92.03%\n",
      "  Epoch 6: Train Loss = 0.1562, Train Acc = 94.28% | Val Loss = 0.2143, Val Acc = 92.60%\n",
      "  Epoch 7: Train Loss = 0.1384, Train Acc = 94.83% | Val Loss = 0.2388, Val Acc = 91.79%\n",
      "  Epoch 8: Train Loss = 0.1186, Train Acc = 95.69% | Val Loss = 0.2345, Val Acc = 92.42%\n",
      "  Epoch 9: Train Loss = 0.0994, Train Acc = 96.28% | Val Loss = 0.2433, Val Acc = 92.25%\n",
      "  Epoch 10: Train Loss = 0.0808, Train Acc = 97.05% | Val Loss = 0.2549, Val Acc = 92.23%\n",
      "  Epoch 11: Train Loss = 0.0695, Train Acc = 97.45% | Val Loss = 0.2640, Val Acc = 92.41%\n",
      "  Epoch 12: Train Loss = 0.0569, Train Acc = 97.90% | Val Loss = 0.3040, Val Acc = 91.99%\n",
      "  Epoch 13: Train Loss = 0.0492, Train Acc = 98.23% | Val Loss = 0.3113, Val Acc = 92.43%\n",
      "  Epoch 14: Train Loss = 0.0377, Train Acc = 98.67% | Val Loss = 0.3198, Val Acc = 92.29%\n",
      "  Epoch 15: Train Loss = 0.0322, Train Acc = 98.84% | Val Loss = 0.3476, Val Acc = 91.95%\n",
      "  Epoch 16: Train Loss = 0.0288, Train Acc = 99.02% | Val Loss = 0.3891, Val Acc = 91.81%\n",
      "  Epoch 17: Train Loss = 0.0305, Train Acc = 98.89% | Val Loss = 0.3809, Val Acc = 92.07%\n",
      "  Epoch 18: Train Loss = 0.0255, Train Acc = 99.09% | Val Loss = 0.3958, Val Acc = 92.17%\n",
      "  Epoch 19: Train Loss = 0.0188, Train Acc = 99.34% | Val Loss = 0.4198, Val Acc = 92.22%\n",
      "  Epoch 20: Train Loss = 0.0196, Train Acc = 99.33% | Val Loss = 0.4514, Val Acc = 92.18%\n",
      "  Epoch 21: Train Loss = 0.0231, Train Acc = 99.20% | Val Loss = 0.4334, Val Acc = 92.08%\n",
      "  Epoch 22: Train Loss = 0.0142, Train Acc = 99.51% | Val Loss = 0.4736, Val Acc = 91.99%\n",
      "  Epoch 23: Train Loss = 0.0134, Train Acc = 99.55% | Val Loss = 0.5389, Val Acc = 91.69%\n",
      "  Epoch 24: Train Loss = 0.0183, Train Acc = 99.37% | Val Loss = 0.4881, Val Acc = 91.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 15:01:47,197] Trial 35 finished with value: 92.6 and parameters: {'batch_size': 96, 'num_epochs': 25, 'learning_rate': 0.0010617885768445885}. Best is trial 31 with value: 92.95833333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25: Train Loss = 0.0159, Train Acc = 99.47% | Val Loss = 0.5030, Val Acc = 92.12%\n",
      "Trial 36: Using device: mps, LR: 0.000386, Batch Size: 80, Epochs: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 15:01:58,103] Trial 36 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 1: Train Loss = 0.5169, Train Acc = 81.77% | Val Loss = 0.4289, Val Acc = 84.15%\n",
      "Trial 37: Using device: mps, LR: 0.003123, Batch Size: 144, Epochs: 20\n",
      "  Epoch 1: Train Loss = 0.4350, Train Acc = 84.08% | Val Loss = 0.3003, Val Acc = 88.88%\n",
      "  Epoch 2: Train Loss = 0.2720, Train Acc = 89.93% | Val Loss = 0.2629, Val Acc = 90.51%\n",
      "  Epoch 3: Train Loss = 0.2235, Train Acc = 91.71% | Val Loss = 0.2334, Val Acc = 91.38%\n",
      "  Epoch 4: Train Loss = 0.1946, Train Acc = 92.73% | Val Loss = 0.2440, Val Acc = 90.73%\n",
      "  Epoch 5: Train Loss = 0.1654, Train Acc = 93.86% | Val Loss = 0.2314, Val Acc = 92.04%\n",
      "  Epoch 6: Train Loss = 0.1439, Train Acc = 94.59% | Val Loss = 0.2366, Val Acc = 92.06%\n",
      "  Epoch 7: Train Loss = 0.1238, Train Acc = 95.25% | Val Loss = 0.2339, Val Acc = 92.15%\n",
      "  Epoch 8: Train Loss = 0.1040, Train Acc = 96.13% | Val Loss = 0.2766, Val Acc = 91.38%\n",
      "  Epoch 9: Train Loss = 0.0912, Train Acc = 96.58% | Val Loss = 0.2748, Val Acc = 91.62%\n",
      "  Epoch 10: Train Loss = 0.0821, Train Acc = 96.94% | Val Loss = 0.3075, Val Acc = 91.67%\n",
      "  Epoch 11: Train Loss = 0.0653, Train Acc = 97.51% | Val Loss = 0.3380, Val Acc = 91.51%\n",
      "  Epoch 12: Train Loss = 0.0580, Train Acc = 97.83% | Val Loss = 0.3693, Val Acc = 91.58%\n",
      "  Epoch 13: Train Loss = 0.0564, Train Acc = 97.97% | Val Loss = 0.3971, Val Acc = 91.42%\n",
      "  Epoch 14: Train Loss = 0.0556, Train Acc = 97.95% | Val Loss = 0.3793, Val Acc = 92.00%\n",
      "  Epoch 15: Train Loss = 0.0479, Train Acc = 98.28% | Val Loss = 0.4092, Val Acc = 91.85%\n",
      "  Epoch 16: Train Loss = 0.0429, Train Acc = 98.47% | Val Loss = 0.4135, Val Acc = 91.12%\n",
      "  Epoch 17: Train Loss = 0.0498, Train Acc = 98.29% | Val Loss = 0.4660, Val Acc = 91.29%\n",
      "  Epoch 18: Train Loss = 0.0353, Train Acc = 98.67% | Val Loss = 0.4997, Val Acc = 91.22%\n",
      "  Epoch 19: Train Loss = 0.0278, Train Acc = 99.01% | Val Loss = 0.4940, Val Acc = 91.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 15:04:45,104] Trial 37 finished with value: 92.15 and parameters: {'batch_size': 144, 'num_epochs': 20, 'learning_rate': 0.003122622003849581}. Best is trial 31 with value: 92.95833333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 20: Train Loss = 0.0354, Train Acc = 98.82% | Val Loss = 0.5388, Val Acc = 91.38%\n",
      "Trial 38: Using device: mps, LR: 0.000972, Batch Size: 128, Epochs: 25\n",
      "  Epoch 1: Train Loss = 0.4846, Train Acc = 82.64% | Val Loss = 0.3159, Val Acc = 88.72%\n",
      "  Epoch 2: Train Loss = 0.3095, Train Acc = 88.89% | Val Loss = 0.2724, Val Acc = 90.14%\n",
      "  Epoch 3: Train Loss = 0.2581, Train Acc = 90.64% | Val Loss = 0.2621, Val Acc = 90.65%\n",
      "  Epoch 4: Train Loss = 0.2287, Train Acc = 91.64% | Val Loss = 0.2548, Val Acc = 90.57%\n",
      "  Epoch 5: Train Loss = 0.2039, Train Acc = 92.58% | Val Loss = 0.2368, Val Acc = 91.60%\n",
      "  Epoch 6: Train Loss = 0.1830, Train Acc = 93.21% | Val Loss = 0.2344, Val Acc = 91.57%\n",
      "  Epoch 7: Train Loss = 0.1653, Train Acc = 93.99% | Val Loss = 0.2326, Val Acc = 91.86%\n",
      "  Epoch 8: Train Loss = 0.1453, Train Acc = 94.59% | Val Loss = 0.2334, Val Acc = 92.10%\n",
      "  Epoch 9: Train Loss = 0.1303, Train Acc = 95.11% | Val Loss = 0.2287, Val Acc = 92.28%\n",
      "  Epoch 10: Train Loss = 0.1144, Train Acc = 95.81% | Val Loss = 0.2426, Val Acc = 92.11%\n",
      "  Epoch 11: Train Loss = 0.1006, Train Acc = 96.25% | Val Loss = 0.2453, Val Acc = 92.45%\n",
      "  Epoch 12: Train Loss = 0.0858, Train Acc = 96.82% | Val Loss = 0.2552, Val Acc = 92.18%\n",
      "  Epoch 13: Train Loss = 0.0747, Train Acc = 97.31% | Val Loss = 0.2572, Val Acc = 92.44%\n",
      "  Epoch 14: Train Loss = 0.0677, Train Acc = 97.54% | Val Loss = 0.2931, Val Acc = 92.27%\n",
      "  Epoch 15: Train Loss = 0.0540, Train Acc = 98.08% | Val Loss = 0.3004, Val Acc = 92.35%\n",
      "  Epoch 16: Train Loss = 0.0477, Train Acc = 98.29% | Val Loss = 0.3166, Val Acc = 92.29%\n",
      "  Epoch 17: Train Loss = 0.0404, Train Acc = 98.56% | Val Loss = 0.3280, Val Acc = 92.28%\n",
      "  Epoch 18: Train Loss = 0.0392, Train Acc = 98.61% | Val Loss = 0.3407, Val Acc = 92.14%\n",
      "  Epoch 19: Train Loss = 0.0320, Train Acc = 98.85% | Val Loss = 0.3708, Val Acc = 92.01%\n",
      "  Epoch 20: Train Loss = 0.0293, Train Acc = 98.95% | Val Loss = 0.3945, Val Acc = 91.69%\n",
      "  Epoch 21: Train Loss = 0.0240, Train Acc = 99.17% | Val Loss = 0.4133, Val Acc = 92.11%\n",
      "  Epoch 22: Train Loss = 0.0203, Train Acc = 99.25% | Val Loss = 0.4331, Val Acc = 91.99%\n",
      "  Epoch 23: Train Loss = 0.0208, Train Acc = 99.26% | Val Loss = 0.4295, Val Acc = 92.20%\n",
      "  Epoch 24: Train Loss = 0.0228, Train Acc = 99.21% | Val Loss = 0.4271, Val Acc = 92.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 15:08:23,212] Trial 38 finished with value: 92.45 and parameters: {'batch_size': 128, 'num_epochs': 25, 'learning_rate': 0.0009716696380079556}. Best is trial 31 with value: 92.95833333333333.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 25: Train Loss = 0.0217, Train Acc = 99.22% | Val Loss = 0.4820, Val Acc = 91.77%\n",
      "Trial 39: Using device: mps, LR: 0.000404, Batch Size: 96, Epochs: 20\n",
      "  Epoch 1: Train Loss = 0.5427, Train Acc = 80.69% | Val Loss = 0.4085, Val Acc = 85.12%\n",
      "  Epoch 2: Train Loss = 0.3448, Train Acc = 87.65% | Val Loss = 0.3272, Val Acc = 88.26%\n",
      "  Epoch 3: Train Loss = 0.2996, Train Acc = 89.20% | Val Loss = 0.3042, Val Acc = 89.06%\n",
      "  Epoch 4: Train Loss = 0.2695, Train Acc = 90.13% | Val Loss = 0.2881, Val Acc = 89.62%\n",
      "  Epoch 5: Train Loss = 0.2456, Train Acc = 91.04% | Val Loss = 0.2563, Val Acc = 90.82%\n",
      "  Epoch 6: Train Loss = 0.2267, Train Acc = 91.74% | Val Loss = 0.2628, Val Acc = 90.54%\n",
      "  Epoch 7: Train Loss = 0.2114, Train Acc = 92.28% | Val Loss = 0.2531, Val Acc = 90.54%\n",
      "  Epoch 8: Train Loss = 0.1974, Train Acc = 92.75% | Val Loss = 0.2614, Val Acc = 90.60%\n",
      "  Epoch 9: Train Loss = 0.1799, Train Acc = 93.41% | Val Loss = 0.2317, Val Acc = 91.72%\n",
      "  Epoch 10: Train Loss = 0.1685, Train Acc = 93.81% | Val Loss = 0.2409, Val Acc = 91.36%\n",
      "  Epoch 11: Train Loss = 0.1558, Train Acc = 94.22% | Val Loss = 0.2359, Val Acc = 91.19%\n",
      "  Epoch 12: Train Loss = 0.1443, Train Acc = 94.67% | Val Loss = 0.2448, Val Acc = 91.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-26 15:37:29,546] Trial 39 pruned. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 13: Train Loss = 0.1319, Train Acc = 95.23% | Val Loss = 0.2328, Val Acc = 91.78%\n",
      "\n",
      "--- Optuna Optimization Finished ---\n",
      "Number of finished trials:  40\n",
      "Best trial:\n",
      "  Value: 92.9583 (Best Validation Accuracy)\n",
      "  Params: \n",
      "    batch_size: 112\n",
      "    num_epochs: 25\n",
      "    learning_rate: 0.0007801093520990975\n"
     ]
    }
   ],
   "source": [
    "db_storage_path = \"sqlite:///fashion_mnist_hpo.db\"\n",
    "\n",
    "study = optuna.create_study(\n",
    "    study_name=\"fashion_mnist_cnn_hpo_study\",\n",
    "    direction=\"maximize\",\n",
    "    storage=db_storage_path,\n",
    "    load_if_exists=True,\n",
    ")\n",
    "\n",
    "print(\"\\n--- Starting Optuna Hyperparameter Optimization ---\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "\n",
    "print(\"\\n--- Optuna Optimization Finished ---\")\n",
    "print(\"Number of finished trials: \", len(study.trials))\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(f\"  Value: {trial.value:.4f} (Best Validation Accuracy)\")\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "caf635b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 112, 'num_epochs': 25, 'learning_rate': 0.0007801093520990975}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1c9ef24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Training Loss: 0.4878, Training Accuracy: 0.8264\n",
      "Epoch 1/25, Validation Loss: 0.3576, Validation Accuracy: 0.8672\n",
      "-----------------------------------------------------\n",
      "Epoch 2/25, Training Loss: 0.3113, Training Accuracy: 0.8893\n",
      "Epoch 2/25, Validation Loss: 0.2849, Validation Accuracy: 0.8938\n",
      "-----------------------------------------------------\n",
      "Epoch 3/25, Training Loss: 0.2619, Training Accuracy: 0.9052\n",
      "Epoch 3/25, Validation Loss: 0.2551, Validation Accuracy: 0.9066\n",
      "-----------------------------------------------------\n",
      "Epoch 4/25, Training Loss: 0.2317, Training Accuracy: 0.9160\n",
      "Epoch 4/25, Validation Loss: 0.2313, Validation Accuracy: 0.9142\n",
      "-----------------------------------------------------\n",
      "Epoch 5/25, Training Loss: 0.2068, Training Accuracy: 0.9256\n",
      "Epoch 5/25, Validation Loss: 0.2349, Validation Accuracy: 0.9140\n",
      "-----------------------------------------------------\n",
      "Epoch 6/25, Training Loss: 0.1843, Training Accuracy: 0.9325\n",
      "Epoch 6/25, Validation Loss: 0.2293, Validation Accuracy: 0.9143\n",
      "-----------------------------------------------------\n",
      "Epoch 7/25, Training Loss: 0.1671, Training Accuracy: 0.9381\n",
      "Epoch 7/25, Validation Loss: 0.2245, Validation Accuracy: 0.9167\n",
      "-----------------------------------------------------\n",
      "Epoch 8/25, Training Loss: 0.1517, Training Accuracy: 0.9440\n",
      "Epoch 8/25, Validation Loss: 0.2232, Validation Accuracy: 0.9187\n",
      "-----------------------------------------------------\n",
      "Epoch 9/25, Training Loss: 0.1333, Training Accuracy: 0.9512\n",
      "Epoch 9/25, Validation Loss: 0.2142, Validation Accuracy: 0.9236\n",
      "-----------------------------------------------------\n",
      "Epoch 10/25, Training Loss: 0.1160, Training Accuracy: 0.9577\n",
      "Epoch 10/25, Validation Loss: 0.2118, Validation Accuracy: 0.9261\n",
      "-----------------------------------------------------\n",
      "Epoch 11/25, Training Loss: 0.1076, Training Accuracy: 0.9603\n",
      "Epoch 11/25, Validation Loss: 0.2232, Validation Accuracy: 0.9272\n",
      "-----------------------------------------------------\n",
      "Epoch 12/25, Training Loss: 0.0922, Training Accuracy: 0.9662\n",
      "Epoch 12/25, Validation Loss: 0.2355, Validation Accuracy: 0.9208\n",
      "-----------------------------------------------------\n",
      "Epoch 13/25, Training Loss: 0.0803, Training Accuracy: 0.9704\n",
      "Epoch 13/25, Validation Loss: 0.2557, Validation Accuracy: 0.9233\n",
      "-----------------------------------------------------\n",
      "Epoch 14/25, Training Loss: 0.0678, Training Accuracy: 0.9760\n",
      "Epoch 14/25, Validation Loss: 0.2670, Validation Accuracy: 0.9190\n",
      "-----------------------------------------------------\n",
      "Epoch 15/25, Training Loss: 0.0591, Training Accuracy: 0.9788\n",
      "Epoch 15/25, Validation Loss: 0.2639, Validation Accuracy: 0.9230\n",
      "-----------------------------------------------------\n",
      "Epoch 16/25, Training Loss: 0.0512, Training Accuracy: 0.9816\n",
      "Epoch 16/25, Validation Loss: 0.2878, Validation Accuracy: 0.9181\n",
      "-----------------------------------------------------\n",
      "Epoch 17/25, Training Loss: 0.0449, Training Accuracy: 0.9844\n",
      "Epoch 17/25, Validation Loss: 0.2812, Validation Accuracy: 0.9224\n",
      "-----------------------------------------------------\n",
      "Epoch 18/25, Training Loss: 0.0351, Training Accuracy: 0.9877\n",
      "Epoch 18/25, Validation Loss: 0.3115, Validation Accuracy: 0.9242\n",
      "-----------------------------------------------------\n",
      "Epoch 19/25, Training Loss: 0.0358, Training Accuracy: 0.9874\n",
      "Epoch 19/25, Validation Loss: 0.3057, Validation Accuracy: 0.9223\n",
      "-----------------------------------------------------\n",
      "Epoch 20/25, Training Loss: 0.0267, Training Accuracy: 0.9909\n",
      "Epoch 20/25, Validation Loss: 0.3691, Validation Accuracy: 0.9193\n",
      "-----------------------------------------------------\n",
      "Epoch 21/25, Training Loss: 0.0257, Training Accuracy: 0.9912\n",
      "Epoch 21/25, Validation Loss: 0.3555, Validation Accuracy: 0.9222\n",
      "-----------------------------------------------------\n",
      "Epoch 22/25, Training Loss: 0.0244, Training Accuracy: 0.9912\n",
      "Epoch 22/25, Validation Loss: 0.3695, Validation Accuracy: 0.9203\n",
      "-----------------------------------------------------\n",
      "Epoch 23/25, Training Loss: 0.0196, Training Accuracy: 0.9928\n",
      "Epoch 23/25, Validation Loss: 0.3961, Validation Accuracy: 0.9258\n",
      "-----------------------------------------------------\n",
      "Epoch 24/25, Training Loss: 0.0221, Training Accuracy: 0.9918\n",
      "Epoch 24/25, Validation Loss: 0.3842, Validation Accuracy: 0.9240\n",
      "-----------------------------------------------------\n",
      "Epoch 25/25, Training Loss: 0.0195, Training Accuracy: 0.9933\n",
      "Epoch 25/25, Validation Loss: 0.4123, Validation Accuracy: 0.9263\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = SimpleCNN(input_shape, number_classes)\n",
    "train_model(model, \n",
    "             batch_size=study.best_params['batch_size'], \n",
    "             num_epochs=study.best_params['num_epochs'], \n",
    "             lr=study.best_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730f6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
